{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2. Create directories and datasets\n",
    "Joona Klemetti   \n",
    "22.2.2018   \n",
    "Cognitive Systems for Health Technology Applications   \n",
    "Helsinki Metropolia University of Applied Science   \n",
    "\n",
    "## Introduction\n",
    "This script is for: \n",
    "1. Checking how many samples are in the original downloaded dataset\n",
    "2. Creating the directory structure for the datasets\n",
    "3. Creating the directories\n",
    "4. Splitting the data into train, validation, and test sets\n",
    "5. Coping the data into the directories\n",
    "\n",
    "Dataset is downloaded from: https://github.com/Nomikxyz/retinopathy-dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check the downloaded data\n",
    "First it is needed to check that we have access to the downloaded and extracted data. This script reads the filenames in `nosymptoms` and `sympotms` subfoldes and counts how many observations are there totally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1468, 595)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all filenames in the master dataset and count how many samples there are\n",
    "original_dir = 'C:\\\\Users\\\\Joona\\\\retinopathy-dataset-master'\n",
    "\n",
    "class1 = 'nosymptoms'\n",
    "original_nosymptoms_dir = os.path.join(original_dir, class1)\n",
    "nosymptoms_fnames = os.listdir(original_nosymptoms_dir)\n",
    "\n",
    "class2 = 'symptoms'\n",
    "original_symptoms_dir = os.path.join(original_dir, class2)\n",
    "symptoms_fnames = os.listdir(original_symptoms_dir)\n",
    "\n",
    "len(nosymptoms_fnames), len(symptoms_fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Directory structure\n",
    "After that it is needed to create the names for the directories and save them into variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base directory is where the datasets will be created\n",
    "base_dir = 'dataset2'\n",
    "\n",
    "# For training set\n",
    "sub_dir = 'train'\n",
    "train_dir = os.path.join(base_dir, sub_dir)\n",
    "train_nosymptoms_dir = os.path.join(base_dir, sub_dir, class1)\n",
    "train_symptoms_dir = os.path.join(base_dir, sub_dir, class2)\n",
    "\n",
    "# For validation set\n",
    "sub_dir = 'validation'\n",
    "validation_dir = os.path.join(base_dir, sub_dir)\n",
    "validation_nosymptoms_dir = os.path.join(base_dir, sub_dir, class1)\n",
    "validation_symptoms_dir = os.path.join(base_dir, sub_dir, class2)\n",
    "\n",
    "# For test set\n",
    "sub_dir = 'test'\n",
    "test_dir = os.path.join(base_dir, sub_dir)\n",
    "test_nosymptoms_dir = os.path.join(base_dir, sub_dir, class1)\n",
    "test_symptoms_dir = os.path.join(base_dir, sub_dir, class2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create directories\n",
    "Next script is checked if the folder already exists. If there is not folders alredy folders are created the directory structure for the train, test, and evaluation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset folders to: dataset2\n"
     ]
    }
   ],
   "source": [
    "if not(os.path.exists(base_dir)):\n",
    "    print('Creating dataset folders to:', base_dir)\n",
    "    os.mkdir(base_dir)\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(train_nosymptoms_dir)\n",
    "    os.mkdir(train_symptoms_dir)\n",
    "    os.mkdir(validation_dir)\n",
    "    os.mkdir(validation_nosymptoms_dir)\n",
    "    os.mkdir(validation_symptoms_dir)\n",
    "    os.mkdir(test_dir)\n",
    "    os.mkdir(test_nosymptoms_dir)\n",
    "    os.mkdir(test_symptoms_dir)\n",
    "else:\n",
    "    print(base_dir, 'already exists!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split the data filenames into train, validation and test sets\n",
    "When the directories are ready, it is time to split the original dataset into training, validation and test sets. For that we use scikit-learn library's train_test_split function. First we split the dataset with rule 80%-20% and then we split 80% to 60% and 20%. Finally we get:\n",
    "- 60% training set\n",
    "- 20% validation set, and \n",
    "- 20% test set.\n",
    "\n",
    "This needs to be repeated both for the healthy (nosymptoms) and disease (symptom) cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(357, 119, 119)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Disease (symptom) cases split\n",
    "\n",
    "# Take 20 % out for testing\n",
    "train_symptoms_fnames, test_symptoms_fnames = train_test_split(symptoms_fnames, test_size = 0.2)\n",
    "\n",
    "# From the remaining 80% take 0.25 (=0.8*0.25 = 20% of total) out for validation\n",
    "train_symptoms_fnames, validation_symptoms_fnames = train_test_split(train_symptoms_fnames, test_size = 0.25)\n",
    "\n",
    "len(train_symptoms_fnames), len(validation_symptoms_fnames), len(test_symptoms_fnames)\n",
    "# For debugging purposes, remove the comment marks.\n",
    "# print(train_symptoms_fnames)\n",
    "# print(validation_symptoms_fnames)\n",
    "# print(test_symptoms_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 294, 294)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Healthy (nosyptom) cases split\n",
    "\n",
    "# Take 20 % out for testing\n",
    "train_nosymptoms_fnames, test_nosymptoms_fnames = train_test_split(nosymptoms_fnames, test_size = 0.2)\n",
    "\n",
    "# From the remaining 80% take 0.25 (20% of total) out for validation\n",
    "train_nosymptoms_fnames, validation_nosymptoms_fnames = train_test_split(train_nosymptoms_fnames, test_size = 0.25)\n",
    "\n",
    "len(train_nosymptoms_fnames), len(validation_nosymptoms_fnames), len(test_nosymptoms_fnames)\n",
    "# For debugging purposes, remove the comment marks.\n",
    "# print(train_nosymptoms_fnames)\n",
    "# print(validation_nosymptoms_fnames)\n",
    "# print(test_nosymptoms_fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Copy data into the directories\n",
    "Finally the original data is copied into the training, validation and test directories. As this might take some time, it is wantd to watch the time spend on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 242.76 sec\n"
     ]
    }
   ],
   "source": [
    "tStart = time.time()\n",
    "\n",
    "# Copy the original files into the dataset folders\n",
    "\n",
    "# Training set\n",
    "# Disease \n",
    "for fname in train_symptoms_fnames:\n",
    "    src = os.path.join(original_symptoms_dir, fname)\n",
    "    dst = os.path.join(train_symptoms_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "# Healthy \n",
    "for fname in train_nosymptoms_fnames:\n",
    "    src = os.path.join(original_nosymptoms_dir, fname)\n",
    "    dst = os.path.join(train_nosymptoms_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# Validation set\n",
    "# Disease \n",
    "for fname in validation_symptoms_fnames:\n",
    "    src = os.path.join(original_symptoms_dir, fname)\n",
    "    dst = os.path.join(validation_symptoms_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "# Healthy\n",
    "for fname in validation_nosymptoms_fnames:\n",
    "    src = os.path.join(original_nosymptoms_dir, fname)\n",
    "    dst = os.path.join(validation_nosymptoms_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# Test set\n",
    "# Disease\n",
    "for fname in test_symptoms_fnames:\n",
    "    src = os.path.join(original_symptoms_dir, fname)\n",
    "    dst = os.path.join(test_symptoms_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "# Healthy\n",
    "for fname in test_nosymptoms_fnames:\n",
    "    src = os.path.join(original_nosymptoms_dir, fname)\n",
    "    dst = os.path.join(test_nosymptoms_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "tStop = time.time()\n",
    "tElapsed = tStop - tStart\n",
    "print('Time elapsed: {:.2f} sec'.format(tElapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Now the directories and dataset are ready for training, validating and testing our convolutional neural networks to make predictions for retinopathy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
